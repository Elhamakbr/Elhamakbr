#Step 1: Cutting videos into sub-videos to reduce the size of the input data
import cv2
import os



# Function to split the video into smaller subvideos with specific number of frames. The number of frames depends on the data collection. 
#For this analysis, this number is equal to the number of frames recorded after detection of an objects in the camera field of view which is called triggering. 
def split_video(input_video_path, output_folder, frames_per_subvideo=200):
    # Check if the output directory exists, create it if it doesn't
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Open the input video
    video_capture = cv2.VideoCapture(input_video_path)
    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = video_capture.get(cv2.CAP_PROP_FPS)
    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_size = (width, height)
    
    # Calculate the number of subvideos needed
    num_subvideos = total_frames // frames_per_subvideo
    remainder_frames = total_frames % frames_per_subvideo
    
    # Adjust the number of subvideos to include the remainder in the last subvideo
    if remainder_frames > 0:
        num_subvideos += 1
    
    print(f"Total frames: {total_frames}")
    print(f"Splitting into {num_subvideos} subvideos...")

    for subvideo_index in range(num_subvideos):
        # Define the filename for each subvideo
        output_filename = os.path.join(output_folder, f"subvideo_{subvideo_index+1}.avi")
        
        # Set up the video writer for each subvideo
        video_writer = cv2.VideoWriter(
            output_filename, 
            cv2.VideoWriter_fourcc(*'XVID'), 
            fps, 
            frame_size
        )

        # Set the frame range for this subvideo
        start_frame = subvideo_index * frames_per_subvideo
        end_frame = min((subvideo_index + 1) * frames_per_subvideo, total_frames)  # Handle remaining frames
        
        print(f"Writing frames {start_frame} to {end_frame - 1} to {output_filename}")
        
        # Read and write frames to the subvideo
        for frame_num in range(start_frame, end_frame):
            video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
            ret, frame = video_capture.read()
            
            if not ret:
                break  # If we fail to read a frame, exit the loop
            
            video_writer.write(frame)
        
        # Release the writer after writing the subvideo
        video_writer.release()

    # Release the video capture object
    video_capture.release()
    print("All subvideos created and saved.")

# Usage
input_video_path = r'Write_the_movie_trajectory_here'  # Replace with the path to your .avi video
output_folder = r'Write_the _address_of_the_folder_in_which_the_subvidoes_are_being_saved'  # Folder to save the subvideos
frames_per_subvideo = 200  # Number of frames per subvideo

split_video(input_video_path, output_folder, frames_per_subvideo)


#Step 2 detection of objects in sub-videos. This step's code is able to detect objects in brightfield images with the low contrast between the forground and background
#Senario one: The intensity value within one object is heterogenous and after detection there will be some area inside an object with no binary value
#Senario two: The object has the same intesnity value in all frames and within its area

def process_video(input_path, output_path, threshold_value=10):
    # Open the video
    cap = cv2.VideoCapture(input_path)

    # Check if the video was opened successfully
    if not cap.isOpened():
        print(f"Error opening video file: {input_path}")
        return

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    # Read all frames into a list
    frames = []
    for _ in range(frame_count):
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)

    cap.release()

    # Check if any frames were read
    if len(frames) == 0:
        print(f"No frames were read from the video: {input_path}")
        return

    # Get the last frame. Since the last frame doesn't include any object, it is used as the background
    last_frame = frames[-1]

    # Create VideoWriter to save the new video
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height - 20))  # Adjust height for cropping

    # Subtract last frame from each previous frame and process. This step by subtracting the last frame (background) from rest of the frames,
    #only leave the objects in each frame
    for i in range(frame_count - 1):  # Skip the last frame itself
        diff_frame = cv2.absdiff(frames[i], last_frame)  # Subtract frames

        # Convert the diff_frame to grayscale
        diff_gray = cv2.cvtColor(diff_frame, cv2.COLOR_BGR2GRAY)

        # Apply threshold to filter out small differences (noise)
        _, thresholded_frame = cv2.threshold(diff_gray, threshold_value, 255, cv2.THRESH_BINARY)

        # Check if any pixels are detected
        if cv2.countNonZero(thresholded_frame) == 0:
            print(f"No significant changes detected in frame {i}.")
            continue  # Skip writing an empty frame

        # Find contours in the thresholded frame.
        contours, _ = cv2.findContours(thresholded_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Merge objects with neighbors. This part of the code fullfills scenario 1 where the intesnity values in the object is not homogenous. 
        # If an object is less than a size threshold (larger than noise), the code check the intesnity value of its neighboring pixels and if there is any difference, it merges it with its surrounding
        for contour in contours:
            if cv2.contourArea(contour) > 5:  # Check if the object is larger than 5 pixels
                # Merge the object with its neighbors
                merge_with_neighbors(thresholded_frame, contour)    #If the intensity values are homogenous in an object, this step can be skipped. 
                #merge_with_neighbors function is written as step 2-2 after this code
        # Normalize output_frame. Each frame is normalized to its own intesnity range to get the most signal in the binary videos
        output_frame = cv2.normalize(thresholded_frame, None, 0, 255, cv2.NORM_MINMAX)

        # Crop the last 20 pixels in the y direction. It is used to remove the metadata exist with the raw videos
        output_frame_cropped = output_frame[0:frame_height - 20, :]  # Crop height

        # Write the output frame to the video
        out.write(cv2.cvtColor(output_frame_cropped, cv2.COLOR_GRAY2BGR))  # Convert back to BGR for output

    out.release()
    print(f"Processed video saved as: {output_path}")

def process_all_videos(input_folder, output_folder, threshold_value=10):   #Batch processing with adjustable value of thresholding depending on the binary videos and signal to noise
    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Process all AVI videos in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith('.avi'):
            input_path = os.path.join(input_folder, filename)
            output_path = os.path.join(output_folder, f"processed_{filename}")
            print(f"Processing {filename}...")
            process_video(input_path, output_path, threshold_value)
    print("Processing completed.")

#Step 2-2
#Merge with neighbor [embedded code in step 2 function]
def merge_with_neighbors(thresholded_frame, contour):
    # Get the bounding box of the contour
    x, y, w, h = cv2.boundingRect(contour)

    # Define the neighborhood region (3 pixel around)
    neighborhood = thresholded_frame[max(0, y-1):min(thresholded_frame.shape[0], y + h + 1),
                                      max(0, x-1):min(thresholded_frame.shape[1], x + w + 1)]
    
    # Check if any of the neighboring pixels are 255
    if np.any(neighborhood == 255):
        # Set the entire bounding box region to 255
        thresholded_frame[y:y + h, x:x + w] = 255


Step 3: Creating the Z-stack of the binary videos. In this step, some frames in binary videos are removed to be able to see differen state of an object accross time distinguishable
#from its state in the previous frames
def process_video(input_path, output_path, interval=9):   #The interval means the number of frames to remove in between and it should be chosen depending on the vidoe framerate and the objects speed
    # Open the video
    cap = cv2.VideoCapture(input_path)

    # Check if the video was opened successfully
    if not cap.isOpened():
        print(f"Error opening video file: {input_path}")
        return

    # Get video properties
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # Create VideoWriter to save the new video
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Process frames
    for i in range(frame_count):
        ret, frame = cap.read()
        if not ret:
            break
        
        # Only write frames at specified intervals
        if i % interval == 0:
            out.write(frame)

    cap.release()
    out.release()
    print(f"Processed video saved as: {output_path}")

#Batch processing all binary videos
def process_all_videos(input_folder, output_folder, interval=9):
    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Process all AVI videos in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith('.avi'):
            input_path = os.path.join(input_folder, filename)
            output_path = os.path.join(output_folder, f"processed_{filename}")
            print(f"Processing {filename}...")
            process_video(input_path, output_path, interval)
    print("Processing completed.")

# Example usage
output_folder = r'Path_to_the_folder_where_frame_removed_videos are going to be saved'
input_folder = r'Path_to_the_binary_video'
process_all_videos(input_folder, output_folder, interval=9)

#Get Z-stack images which is the maximum average intesnity accross all frames in binary videos featuring removed frames.

def compute_z_stack_maximum(input_path):
    # Open the video
    cap = cv2.VideoCapture(input_path)

    # Check if the video was opened successfully
    if not cap.isOpened():
        print(f"Error opening video file: {input_path}")
        return None

    max_projection = None
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Convert to grayscale for maximum projection (if not already in grayscale)
        # Since it’s binary, we can use it directly
        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Initialize max_projection if it doesn't exist
        if max_projection is None:
            max_projection = gray_frame.astype(np.uint8)
        else:
            # Update the maximum projection
            max_projection = np.maximum(max_projection, gray_frame)

    cap.release()
    
    # Since the max_projection is binary, we can just return it as is
    return max_projection

#Batch processing
def process_all_videos(input_folder, output_folder):
    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Process all AVI videos in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith('.avi'):
            input_path = os.path.join(input_folder, filename)
            print(f"Processing {filename}...")
            z_stack_image = compute_z_stack_maximum(input_path)
            if z_stack_image is not None:
                # Save the Z-stack maximum image
                output_path = os.path.join(output_folder, f"z_stack_max_{filename[:-4]}.png")
                cv2.imwrite(output_path, z_stack_image)
                print(f"Z-stack maximum image saved as: {output_path}")

    print("Processing completed.")

# Example usage
input_folder = r'Path_to_all_binary_videos'
output_folder = r'Path_to_the_folder_where_Z_stack_images_will_be_saved'
process_all_videos(input_folder, output_folder)


