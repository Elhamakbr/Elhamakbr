import cv2
import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

#Step 1: Cutting videos into sub-videos to reduce the size of the input data
# Function to split the video into smaller subvideos with specific number of frames. The number of frames depends on the data collection. 
#For this analysis, this number is equal to the number of frames recorded after detection of an objects in the camera field of view which is called triggering. 
def split_video(input_video_path, output_folder, frames_per_subvideo=200):
    # Check if the output directory exists, create it if it doesn't
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Open the input video
    video_capture = cv2.VideoCapture(input_video_path)
    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = video_capture.get(cv2.CAP_PROP_FPS)
    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_size = (width, height)
    
    # Calculate the number of subvideos needed
    num_subvideos = total_frames // frames_per_subvideo
    remainder_frames = total_frames % frames_per_subvideo
    
    # Adjust the number of subvideos to include the remainder in the last subvideo
    if remainder_frames > 0:
        num_subvideos += 1
    
    print(f"Total frames: {total_frames}")
    print(f"Splitting into {num_subvideos} subvideos...")

    for subvideo_index in range(num_subvideos):
        # Define the filename for each subvideo
        output_filename = os.path.join(output_folder, f"subvideo_{subvideo_index+1}.avi")
        
        # Set up the video writer for each subvideo
        video_writer = cv2.VideoWriter(
            output_filename, 
            cv2.VideoWriter_fourcc(*'XVID'), 
            fps, 
            frame_size
        )

        # Set the frame range for this subvideo
        start_frame = subvideo_index * frames_per_subvideo
        end_frame = min((subvideo_index + 1) * frames_per_subvideo, total_frames)  # Handle remaining frames
        
        print(f"Writing frames {start_frame} to {end_frame - 1} to {output_filename}")
        
        # Read and write frames to the subvideo
        for frame_num in range(start_frame, end_frame):
            video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
            ret, frame = video_capture.read()
            
            if not ret:
                break  # If we fail to read a frame, exit the loop
            
            video_writer.write(frame)
        
        # Release the writer after writing the subvideo
        video_writer.release()

    # Release the video capture object
    video_capture.release()
    print("All subvideos created and saved.")

# Usage
input_video_path = r'Write_the_movie_trajectory_here'  # Replace with the path to your .avi video
output_folder = r'Write_the _address_of_the_folder_in_which_the_subvidoes_are_being_saved'  # Folder to save the subvideos
frames_per_subvideo = 200  # Number of frames per subvideo

split_video(input_video_path, output_folder, frames_per_subvideo)


#Step 2 detection of objects in sub-videos. This step's code is able to detect objects in brightfield images with the low contrast between the forground and background
#Senario one: The intensity value within one object is heterogenous and after detection there will be some area inside an object with no binary value
#Senario two: The object has the same intesnity value in all frames and within its area

def process_video(input_path, output_path, threshold_value=10):
    # Open the video
    cap = cv2.VideoCapture(input_path)

    # Check if the video was opened successfully
    if not cap.isOpened():
        print(f"Error opening video file: {input_path}")
        return

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    # Read all frames into a list
    frames = []
    for _ in range(frame_count):
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)

    cap.release()

    # Check if any frames were read
    if len(frames) == 0:
        print(f"No frames were read from the video: {input_path}")
        return

    # Get the last frame. Since the last frame doesn't include any object, it is used as the background
    last_frame = frames[-1]

    # Create VideoWriter to save the new video
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height - 20))  # Adjust height for cropping

    # Subtract last frame from each previous frame and process. This step by subtracting the last frame (background) from rest of the frames,
    #only leave the objects in each frame
    for i in range(frame_count - 1):  # Skip the last frame itself
        diff_frame = cv2.absdiff(frames[i], last_frame)  # Subtract frames

        # Convert the diff_frame to grayscale
        diff_gray = cv2.cvtColor(diff_frame, cv2.COLOR_BGR2GRAY)

        # Apply threshold to filter out small differences (noise)
        _, thresholded_frame = cv2.threshold(diff_gray, threshold_value, 255, cv2.THRESH_BINARY)

        # Check if any pixels are detected
        if cv2.countNonZero(thresholded_frame) == 0:
            print(f"No significant changes detected in frame {i}.")
            continue  # Skip writing an empty frame

        # Find contours in the thresholded frame.
        contours, _ = cv2.findContours(thresholded_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Merge objects with neighbors. This part of the code fullfills scenario 1 where the intesnity values in the object is not homogenous. 
        # If an object is less than a size threshold (larger than noise), the code check the intesnity value of its neighboring pixels and if there is any difference, it merges it with its surrounding
        for contour in contours:
            if cv2.contourArea(contour) > 5:  # Check if the object is larger than 5 pixels
                # Merge the object with its neighbors
                merge_with_neighbors(thresholded_frame, contour)    #If the intensity values are homogenous in an object, this step can be skipped. 
                #merge_with_neighbors function is written as step 2-2 after this code
        # Normalize output_frame. Each frame is normalized to its own intesnity range to get the most signal in the binary videos
        output_frame = cv2.normalize(thresholded_frame, None, 0, 255, cv2.NORM_MINMAX)

        # Crop the last 20 pixels in the y direction. It is used to remove the metadata exist with the raw videos
        output_frame_cropped = output_frame[0:frame_height - 20, :]  # Crop height

        # Write the output frame to the video
        out.write(cv2.cvtColor(output_frame_cropped, cv2.COLOR_GRAY2BGR))  # Convert back to BGR for output

    out.release()
    print(f"Processed video saved as: {output_path}")

def process_all_videos(input_folder, output_folder, threshold_value=10):   #Batch processing with adjustable value of thresholding depending on the binary videos and signal to noise
    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Process all AVI videos in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith('.avi'):
            input_path = os.path.join(input_folder, filename)
            output_path = os.path.join(output_folder, f"processed_{filename}")
            print(f"Processing {filename}...")
            process_video(input_path, output_path, threshold_value)
    print("Processing completed.")

#Step 2-2
#Merge with neighbor [embedded code in step 2 function]
def merge_with_neighbors(thresholded_frame, contour):
    # Get the bounding box of the contour
    x, y, w, h = cv2.boundingRect(contour)

    # Define the neighborhood region (3 pixel around)
    neighborhood = thresholded_frame[max(0, y-1):min(thresholded_frame.shape[0], y + h + 1),
                                      max(0, x-1):min(thresholded_frame.shape[1], x + w + 1)]
    
    # Check if any of the neighboring pixels are 255
    if np.any(neighborhood == 255):
        # Set the entire bounding box region to 255
        thresholded_frame[y:y + h, x:x + w] = 255


Step 3: Creating the Z-stack of the binary videos. In this step, some frames in binary videos are removed to be able to see differen state of an object accross time distinguishable
#from its state in the previous frames
def process_video(input_path, output_path, interval=9):   #The interval means the number of frames to remove in between and it should be chosen depending on the vidoe framerate and the objects speed
    # Open the video
    cap = cv2.VideoCapture(input_path)

    # Check if the video was opened successfully
    if not cap.isOpened():
        print(f"Error opening video file: {input_path}")
        return

    # Get video properties
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # Create VideoWriter to save the new video
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Process frames
    for i in range(frame_count):
        ret, frame = cap.read()
        if not ret:
            break
        
        # Only write frames at specified intervals
        if i % interval == 0:
            out.write(frame)

    cap.release()
    out.release()
    print(f"Processed video saved as: {output_path}")

#Batch processing all binary videos
def process_all_videos(input_folder, output_folder, interval=9):
    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Process all AVI videos in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith('.avi'):
            input_path = os.path.join(input_folder, filename)
            output_path = os.path.join(output_folder, f"processed_{filename}")
            print(f"Processing {filename}...")
            process_video(input_path, output_path, interval)
    print("Processing completed.")

# Example usage
output_folder = r'Path_to_the_folder_where_frame_removed_videos are going to be saved'
input_folder = r'Path_to_the_binary_video'
process_all_videos(input_folder, output_folder, interval=9)

#Get Z-stack images which is the maximum average intesnity accross all frames in binary videos featuring removed frames.

def compute_z_stack_maximum(input_path):
    # Open the video
    cap = cv2.VideoCapture(input_path)

    # Check if the video was opened successfully
    if not cap.isOpened():
        print(f"Error opening video file: {input_path}")
        return None

    max_projection = None
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Convert to grayscale for maximum projection (if not already in grayscale)
        # Since itâ€™s binary, we can use it directly
        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Initialize max_projection if it doesn't exist
        if max_projection is None:
            max_projection = gray_frame.astype(np.uint8)
        else:
            # Update the maximum projection
            max_projection = np.maximum(max_projection, gray_frame)

    cap.release()
    
    # Since the max_projection is binary, we can just return it as is
    return max_projection

#Batch processing
def process_all_videos(input_folder, output_folder):
    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Process all AVI videos in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith('.avi'):
            input_path = os.path.join(input_folder, filename)
            print(f"Processing {filename}...")
            z_stack_image = compute_z_stack_maximum(input_path)
            if z_stack_image is not None:
                # Save the Z-stack maximum image
                output_path = os.path.join(output_folder, f"z_stack_max_{filename[:-4]}.png")
                cv2.imwrite(output_path, z_stack_image)
                print(f"Z-stack maximum image saved as: {output_path}")

    print("Processing completed.")

# Example usage
input_folder = r'Path_to_all_binary_videos'
output_folder = r'Path_to_the_folder_where_Z_stack_images_will_be_saved'
process_all_videos(input_folder, output_folder)


#Step 4: Anlysis of the Z-stack images

#Step 4-1: In this step elipses are fitted to the objects in the binary Z-stack images and data inluding their angle, major and minor axis length and circularity is being calculated
def elipse_drawing(image_path, output_path):
    # Load the grayscale image
    gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Apply Gaussian blur to reduce noise
    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)

    # Apply a binary threshold to the blurred image
    _, thresholded_image = cv2.threshold(blurred_image, 128, 255, cv2.THRESH_BINARY) # this can remove any extra noises

    # Find contours in the preprocessed image using cv2.RETR_CCOMP
    contours, _ = cv2.findContours(thresholded_image, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)

    # Filter out only the external contours based on area
    external_contours = [cnt for cnt in contours if 4000 > cv2.contourArea(cnt) > 3] # This value is based in pixels and should be adjusted depending on the properies of the detected objects

    # Create an empty image to draw contours
    contour_image = np.zeros_like(gray_image, dtype=np.uint8)

    # Draw contours on the empty image
    cv2.drawContours(contour_image, external_contours, -1, (255), thickness=2)

    # Prepare lists to store ellipse properties
    centers = []
    rotation_angles = []
    major_axis_lengths = []
    minor_axis_lengths = []
    circularities = []

    # Fit ellipses to the external contours and calculate properties
    ellipses = []
    for contour in external_contours:
        if len(contour) >= 5:  # FitEllipse requires at least 5 points
            # Fit the ellipse
            ellipse = cv2.fitEllipse(contour)
            ellipses.append(ellipse)
            
            # Calculate the center of mass
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cX = int(M["m10"] / M["m00"])
                cY = int(M["m01"] / M["m00"])
                centers.append((cX, cY))
            
            # Store ellipse properties
            major_axis_lengths.append(ellipse[1][1])  # Major axis length
            minor_axis_lengths.append(ellipse[1][0])  # Minor axis length
            rotation_angles.append(ellipse[2])  # Rotation angle
            
            # Calculate circularity. Circularity here is area/perimeter^2 
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)
            if perimeter != 0:
                circularity = 4 * np.pi * (area / (perimeter ** 2))
            else:
                circularity = 0  # If the perimeter is 0, the circularity is 0
            circularities.append(circularity)

    # Create an empty image to draw ellipses
    ellipse_image = np.zeros_like(gray_image, dtype=np.uint8)

    # Draw ellipses on the image
    for ellipse in ellipses:
        cv2.ellipse(ellipse_image, ellipse, (255), thickness=2)

    # Save the ellipse image
    ellipse_output_path = os.path.join(output_path, f"{os.path.splitext(os.path.basename(image_path))[0]}_ellipses.png")
    cv2.imwrite(ellipse_output_path, ellipse_image)

    # Return the measured properties
    return centers, rotation_angles, major_axis_lengths, minor_axis_lengths, circularities

def process_all_tif_images(input_folder, output_folder):
    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Create a DataFrame to store results
    results_df = pd.DataFrame(columns=['Image Name', 'Center X', 'Center Y', 'Rotation Angle',
                                       'Major Axis Length', 'Minor Axis Length', 'Circularity'])

    # Process all TIF or PNG images in the input folder
    for filename in os.listdir(input_folder):
        if filename.endswith('.png'):  #Change the file type according to your data
            input_path = os.path.join(input_folder, filename)
            print(f"Processing {filename}...")
            centers, rotation_angles, major_axis_lengths, minor_axis_lengths, circularities = elipse_drawing(input_path, output_folder)

            # Append results to the DataFrame
            for i, (center, rotation_angle, major_axis, minor_axis, circularity) in enumerate(zip(centers, rotation_angles, major_axis_lengths, minor_axis_lengths, circularities)):
                results_df = results_df.append({
                    'Image Name': filename,
                    'Center X': center[0],
                    'Center Y': center[1],
                    'Rotation Angle': rotation_angle,
                    'Major Axis Length': major_axis,
                    'Minor Axis Length': minor_axis,
                    'Circularity': circularity
                }, ignore_index=True)

    # Save the DataFrame to a CSV file
    results_csv_path = os.path.join(output_folder, 'ellipse_analysis_results.csv')
    results_df.to_csv(results_csv_path, index=False)
    print(f"Results saved to {results_csv_path}")

# Example usage
input_folder = r'Path_to_the_folder_containing_binary_Z_stack_images'  # Change to your input folder path
output_folder = r'Path_to_the_folder_where elipse_fitted_objects_are_being_saved'  # Change to your output folder path
process_all_tif_images(input_folder, output_folder)


#Step 6: Plotting data and analysis. This step groups the data saved in Pandas dataframe based on properties which narrow separates data corresponds to one object from each
#and then plot different values
def plot_groups(results_df):
    plt.figure(figsize=(24, 4))

    # Group by 'Image Name' 1st step to narrow down the data
    grouped = results_df.groupby('Image Name')

    # List to store unique colors for groups
    #unique_colors = plt.cm.get_cmap('hsv', len(grouped))  # Use 'hsv' colormap for diverse colors. Use this line if you want to have different color corresponds to different group

    # Iterate through each group
    for i, (name, group) in enumerate(grouped):
        # Skip groups with less than 3 members #to avoid ant error in matching objects or using any background-detected object
        if len(group) < 3:
            continue

        # Iterate through each center in the group
        for j in range(len(group)):
            # Get the current center
            center = group.iloc[j]

            # Apply the condition to find centers close in X, Y, and similar in major axis length (within 3)
            close_centers = group[ 
                                  (abs(group['Center Y'] - center['Center Y']) < 10) & #Change the threshold according to data and image pixel size
                                  (abs(group['Major Axis Length'] - center['Major Axis Length']) < 1)& #Change the value according to the type of particles. for a soft particle this value should be larger due to deformation
                                  (group['Major Axis Length'] > 6) & #Change according to the known properties of the detected objects
                                  (group['Major Axis Length'] < 40)]

            # Only plot if there are close centers that satisfy the condition
            if not close_centers.empty:
                # Prepare the data for plotting
                x_values = close_centers['Center X']
                rotation_angles = close_centers['Rotation Angle']
                #Other values such as Center Y, or circularity can be used instead here

                # Plot the rotation angle against the center X position with different color for each group
                plt.scatter(x_values, rotation_angles, marker='o', color='red')

    # Add labels and title (no legend)
    plt.xlabel('Center X')
    plt.ylabel('Rotation Angle')
    plt.title('Rotation Angle vs Center X (Filtered by Close Centers and Major Axis Length)')
    plt.savefig('The_final_plot.pdf')

# Read the data
data = pd.read_csv(r'Path_to_CSV_file\ellipse_analysis_results.csv')

# Call the plotting function with the results DataFrame
plot_groups(data)
